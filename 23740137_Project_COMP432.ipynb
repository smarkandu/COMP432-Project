{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13njqHju_mxceDN0wf9624YXomIqKY25h","timestamp":1679074424629},{"file_id":"1exB2IBtrI9ex0F1O-JZ2Bmf0wJotC-W5","timestamp":1675656994007}],"collapsed_sections":["Dn6srDF_ET8k","PwWyEMi_Lo7W"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"voe0xG57Lo6z"},"source":["# Project"]},{"cell_type":"markdown","source":["# 1.1 Import Libraries"],"metadata":{"id":"Dn6srDF_ET8k"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzSrkqWcLo63","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b8082d7-0a17-4d6c-cd1c-d129a624f6ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/epistimio/orion.git@develop\n","  Cloning https://github.com/epistimio/orion.git (to revision develop) to /tmp/pip-req-build-l79gg7dg\n","  Running command git clone --filter=blob:none --quiet https://github.com/epistimio/orion.git /tmp/pip-req-build-l79gg7dg\n","  Resolved https://github.com/epistimio/orion.git to commit 3a4b49f1f959193520efa15b894d41f19864aa3c\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (2.2.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (6.0)\n","Collecting pymongo>=3\n","  Downloading pymongo-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.1/492.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.10.1)\n","Collecting gitpython\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (3.11.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (0.8.10)\n","Requirement already satisfied: AppDirs in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.4.4)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (5.13.1)\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.5.3)\n","Collecting gunicorn\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting falcon\n","  Downloading falcon-3.1.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting falcon-cors\n","  Downloading falcon-cors-1.1.7.tar.gz (6.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.2.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (5.9.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (1.2.0)\n","Requirement already satisfied: pytest>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from orion==0.2.6.post294+g3a4b49f1) (7.2.2)\n","Collecting scikit-optimize\n","  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n","  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (22.2.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (2.0.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (1.1.1)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (1.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (23.0)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion==0.2.6.post294+g3a4b49f1) (2.0.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.9/dist-packages (from gunicorn->orion==0.2.6.post294+g3a4b49f1) (67.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->orion==0.2.6.post294+g3a4b49f1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->orion==0.2.6.post294+g3a4b49f1) (2022.7.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->orion==0.2.6.post294+g3a4b49f1) (8.2.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->orion==0.2.6.post294+g3a4b49f1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->orion==0.2.6.post294+g3a4b49f1) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->orion==0.2.6.post294+g3a4b49f1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->orion==0.2.6.post294+g3a4b49f1) (2022.12.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->orion==0.2.6.post294+g3a4b49f1) (3.1.0)\n","Collecting pyaml>=16.9\n","  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->orion==0.2.6.post294+g3a4b49f1) (1.16.0)\n","Building wheels for collected packages: orion, falcon-cors\n","  Building wheel for orion (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for orion: filename=orion-0.2.6.post294+g3a4b49f1-py2.py3-none-any.whl size=6669359 sha256=b8aeb05251205a99f6fbf2d4e7da8b25cfe0016ad2142a503c1cab471eadb30f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-v9zimhoy/wheels/76/bf/4a/cf8ee3147e69c44c58d6830136de3c80ae1b133fffd6c04dc0\n","  Building wheel for falcon-cors (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for falcon-cors: filename=falcon_cors-1.1.7-py3-none-any.whl size=6495 sha256=c4be42ea51940bf680e49a52c6d44a80d6d722c1731a02ff9482a59856ff7140\n","  Stored in directory: /root/.cache/pip/wheels/60/a3/51/c57093ca7028d9d7ce1cd76c3d0d7671b8dbc4b4eefc61459d\n","Successfully built orion falcon-cors\n","Installing collected packages: kaleido, smmap, pyaml, gunicorn, falcon, dnspython, pymongo, gitdb, falcon-cors, scikit-optimize, gitpython, orion\n","Successfully installed dnspython-2.3.0 falcon-3.1.1 falcon-cors-1.1.7 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 kaleido-0.2.1 orion-0.2.6.post294+g3a4b49f1 pyaml-21.10.1 pymongo-4.3.3 scikit-optimize-0.9.0 smmap-5.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: orion[profet] in /usr/local/lib/python3.9/dist-packages (0.2.6.post294+g3a4b49f1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (2.2.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.2.2)\n","Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (0.9.0)\n","Requirement already satisfied: pytest>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (7.2.2)\n","Requirement already satisfied: falcon in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (3.1.1)\n","Requirement already satisfied: falcon-cors in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.1.7)\n","Requirement already satisfied: pymongo>=3 in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (4.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (3.11.0)\n","Requirement already satisfied: gunicorn in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (20.1.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (6.0)\n","Requirement already satisfied: gitpython in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (3.1.31)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.10.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.5.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (5.9.4)\n","Requirement already satisfied: AppDirs in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.4.4)\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (0.2.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (5.13.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (0.8.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (2.27.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (1.2.0)\n","Collecting emukit\n","  Downloading emukit-0.4.10.tar.gz (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting GPy\n","  Downloading GPy-1.10.0.tar.gz (959 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.4/959.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pybnn\n","  Downloading pybnn-0.0.5.tar.gz (22 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from orion[profet]) (2.0.0+cu118)\n","Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from pymongo>=3->orion[profet]) (2.3.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (22.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (23.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (2.0.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (1.1.1)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (2.0.1)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest>=3.0.0->orion[profet]) (1.0.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.9/dist-packages (from emukit->orion[profet]) (67.6.1)\n","Collecting emcee>=2.2.1\n","  Downloading emcee-3.1.4-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from gitpython->orion[profet]) (4.0.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from GPy->orion[profet]) (1.16.0)\n","Collecting paramz>=0.9.0\n","  Downloading paramz-0.9.5.tar.gz (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.9/dist-packages (from GPy->orion[profet]) (0.29.34)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->orion[profet]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->orion[profet]) (2022.7.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->orion[profet]) (8.2.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from pybnn->orion[profet]) (0.15.1+cu118)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->orion[profet]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->orion[profet]) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->orion[profet]) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->orion[profet]) (2022.12.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->orion[profet]) (3.1.0)\n","Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize->orion[profet]) (21.10.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->orion[profet]) (3.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->orion[profet]) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->orion[profet]) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->orion[profet]) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->orion[profet]) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->orion[profet]) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->orion[profet]) (16.0.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->gitpython->orion[profet]) (5.0.0)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.9/dist-packages (from GPy->orion[profet]) (3.7.1)\n","Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from paramz>=0.9.0->GPy->orion[profet]) (4.4.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->orion[profet]) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->orion[profet]) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->pybnn->orion[profet]) (8.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (4.39.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (5.12.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0->GPy->orion[profet]) (3.0.9)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0->GPy->orion[profet]) (3.15.0)\n","Building wheels for collected packages: emukit, GPy, pybnn, paramz\n","  Building wheel for emukit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emukit: filename=emukit-0.4.10-py3-none-any.whl size=257071 sha256=3ef83ea2236a2ecee91d7433f82972d1f3d3a5d10a529b62b096a968f13a36c7\n","  Stored in directory: /root/.cache/pip/wheels/9d/87/f4/54faeaf90597394334ce816052e3e827fc014090a64d0af806\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import copy\n","import sklearn\n","import sklearn.preprocessing\n","import sklearn.neural_network\n","\n","np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n","torch.set_printoptions(precision=3, sci_mode=False)\n","!pip install git+https://github.com/epistimio/orion.git@develop\n","!pip install orion[profet]\n"]},{"cell_type":"markdown","source":["# 1.2 User Defined Functions"],"metadata":{"id":"EII7muSQb8j9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYSnlK-dLo67","pycharm":{"is_executing":true}},"outputs":[],"source":["def plot_matrix_grid(V, cmap='bwr'):\n","    \"\"\"\n","    Given an array V containing stacked matrices, plots them in a grid layout.\n","    V should have shape (K,M,N) where V[k] is a matrix of shape (M,N).\n","    The default cmap is \"bwr\" (blue-white-red) but can also be \"gray\".\n","    \"\"\"\n","    if isinstance(V, torch.Tensor):\n","        V = V.detach().numpy()\n","    assert V.ndim == 3, \"Expected V to have 3 dimensions, not %d\" % V.ndim\n","    k, m, n = V.shape\n","    ncol = 8                                     # At most 8 columns\n","    nrow = min(4, (k + ncol - 1) // ncol)        # At most 4 rows\n","    V = V[:nrow*ncol]                            # Focus on just the matrices we'll actually plot\n","    figsize = (2*ncol, max(1, 2*nrow*(m/n)))     # Guess a good figure shape based on ncol, nrow\n","    fig, axes = plt.subplots(nrow, ncol, sharex=True, sharey=True, figsize=figsize)\n","    vmax = np.percentile(np.abs(V), [99.9])      # Show the main range of values, between 0.1%-99.9%\n","    for v, ax in zip(V, axes.flat):\n","        img = ax.matshow(v, vmin=-vmax, vmax=vmax, cmap=plt.get_cmap(cmap))\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","    for ax in axes.flat[len(V):]:\n","        ax.set_axis_off()\n","    fig.colorbar(img, cax=fig.add_axes([0.92, 0.25, 0.01, .5]))   # Add a colorbar on the right    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsfKuyFzLo6_","pycharm":{"is_executing":true}},"outputs":[],"source":["def plot_named_tensors(tensor_dict):\n","    \"\"\"\n","    Given a dict of {name: tensor} pairs, plots the tensors side-by-side in a common\n","    color scale. The name of each tensor is shown above its plot.\n","    \"\"\"\n","    n = len(tensor_dict)\n","    vmax = max(v.abs().max() for v in tensor_dict.values())\n","    figsize = (2*n, 6)\n","    fig, axes = plt.subplots(1, n, figsize=figsize,  constrained_layout=True, squeeze=True)\n","    axes = axes.flat if isinstance(axes, np.ndarray) else (axes,)\n","    for (name, v), ax in zip(tensor_dict.items(), axes):\n","        v = torch.squeeze(v.detach())   # Automatically convert (N,1,D) to (N,D)\n","        if v.ndim == 1:\n","            v = v.view(-1, 1)  # Automatically convert (N,) to (N,1)\n","        assert v.ndim == 2, \"couldn't turn tensors[%d] with shape %s into 2D\" % (i, v.shape)\n","        img = ax.matshow(v, vmin=-vmax, vmax=vmax, cmap=plt.get_cmap('bwr'))\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(name)\n","    fig.colorbar(img, cax=fig.add_axes([0.985, 0.25, 0.03, .5]))   # Add a colorbar on the right    "]},{"cell_type":"code","source":["# From Tutorial from week 5 (Debug)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, transforms\n","torch.manual_seed(1)\n","\n","# Hparams\n","# batch_size=128\n","# epochs=20 \n","# lr=0.005\n","# input_size = 784\n","# hidden_size = 500\n","num_classes = 10 \n","\n","device = \"cpu\"\n","if torch.cuda.is_available():\n","  device = \"cuda\"\n","\n","\n","def train(X_trn, y_trn, model, loss, args, optimizer):\n","  losses=[]\n","  accuracies=[]\n","  model.train()\n","\n","  for i in range(0, len(X_trn), args.batchsize):\n","    images = X_trn[i:i+args.batchsize].to(device)\n","    labels = y_trn[i:i+args.batchsize].to(device)\n","    #print('images.shape',images.shape)\n","    outputs = model(images)\n","    l = loss(outputs, labels)\n","    l.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","    losses.append(l.item())\n","    \n","    # Append Accuracy\n","    predictions = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    accuracies.append(sum(predictions == labels).item()/args.batchsize)\n","  return torch.tensor(losses).mean(), torch.tensor(accuracies).mean()\n","\n","def test(X_tst, y_tst, model, loss, args):\n","  losses=[]\n","  accuracies=[]\n","  err=0\n","  model.eval()\n","  for i in range(0, len(X_tst), args.batchsize):\n","    images = X_tst[i:i+args.batchsize].to(device)\n","    labels = y_tst[i:i+args.batchsize].to(device)\n","    outputs = model(images)\n","    l = loss(outputs, labels)\n","    losses.append(l.item())\n","\n","    predictions = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    accuracies.append(sum(predictions == labels).item()/args.batchsize)\n","    err = err + (predictions!=labels).sum().item()\n","  return torch.tensor(losses).mean(), err/len(X_tst), torch.tensor(accuracies).mean()\n","\n","# Training loop\n","def plot_epochs(X_trn, y_trn, X_tst, y_tst, model, loss, args, plot=False):\n","  train_losses=[]\n","  test_losses=[]\n","  train_accuracies=[]\n","  test_accuracies=[]\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weightdecay)\n","\n","  for epoch in range(args.epochs):\n","    train_loss, train_accuracy = train(X_trn, y_trn, model, loss, args, optimizer)\n","    test_loss, test_err, test_accuracy = test(X_tst, y_tst, model, loss, args)\n","    train_losses.append(train_loss)\n","    test_losses.append(test_loss)\n","    train_accuracies.append(train_accuracy)\n","    test_accuracies.append(test_accuracy)\n","    print('Epoch: {}  train_loss={:.4f}, test_loss={:.4f}, test_err={:.2f}%, train_accuracy={:.2f}%, test_accuracy={:.2f}%' \\\n","      .format(epoch+1, train_loss, test_loss, test_err*100, train_accuracy*100, test_accuracy*100))\n","\n","  if plot == True:\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1,2,1)\n","    plt.plot(train_losses, '-s', label='train')\n","    plt.plot(test_losses, '-s', label='test')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    plt.subplot(1,2,2)\n","    plt.plot(train_accuracies, '-s', label='train')\n","    plt.plot(test_accuracies, '-s', label='test')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    plt.show()\n","\n","  return train_accuracies[-1], test_accuracies[-1]\n","\n","# Preprocess Image\n","# From https://huggingface.co/spaces/pytorch/ResNet/blob/main/app.py\n","def preprocess_image(input_image):\n","  preprocess = transforms.Compose([\n","      transforms.Resize(256),\n","      transforms.CenterCrop(224),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","  ])\n","  input_tensor = preprocess(input_image);\n","    \n","  return input_tensor;\n"],"metadata":{"id":"RS6YveAJErve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PwWyEMi_Lo7W"},"source":["<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n","<div style=\"border-bottom: 3px solid black\"></div>\n","\n","# 2. Getting data\n","\n","Data obtained from the following dataset in Kaggle:\n","https://www.kaggle.com/datasets/moodrammer/handdrawn-circuit-schematic-components"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"ybUQQMm2Lo7X"},"outputs":[],"source":["def get_data():\n","  data_retrieval = 0\n","\n","  if data_retrieval == 0:\n","    !gdown 11Psi1ZZ2WJ-oHCG1UZcyjGQ1N1iFllDf\n","    path_for_npz = \"data.npz\"\n","\n","  else:\n","    colab_notebook_root = \"/content/drive/MyDrive/Colab Notebooks\"\n","    path_for_npz = colab_notebook_root + \"/COMP 432/Project/npz/data.npz\"\n","    if data_retrieval == 1:\n","        path_for_npz = \"G:/My Drive/Colab Notebooks/COMP 432/Project/npz/data.npz\"\n","    else:\n","        from google.colab import drive\n","        drive.mount(\"/content/drive\")\n","\n","  #!gdown 11Psi1ZZ2WJ-oHCG1UZcyjGQ1N1iFllDf\n","  #!rm data.npz\n","  #!find data.npz\n","\n","  with np.load(path_for_npz) as data:\n","    X = data['X']\n","    print(X.shape)\n","    X = X[:,:,:,2] # Get one channel\n","    print('X.shape', X.shape)\n","    X = X.reshape(-1, 1, 120, 120)\n","    X = X / 255.0 #Normalize data\n","\n","    y = data['y']\n","    print('y.shape', y.shape)\n","    # Encode labels to integers\n","    from sklearn import preprocessing\n","    le = preprocessing.LabelEncoder()\n","    le.fit(y)\n","    print('label classes', le.classes_.shape)\n","    y = le.transform(y)\n","\n","    return X, y\n","\n","X, y = get_data()"]},{"cell_type":"code","source":["print('X.shape',X.shape)\n","print('y.shape', y.shape)\n","# Your code for printing sample values. Aim for 2 lines.\n","print(X[0][400:415])\n","# Your code for printing sample values. Aim for 2 lines.\n","print(y[1:5])\n","#print(X_trn)\n","print('Min X', np.min(X))\n","print('Max X', np.max(X))"],"metadata":{"id":"5jsmZsfRtr1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split train and test data (aim for 1 line)\n","def get_and_split_data(train_size):\n","  X, y = get_data()\n","  X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, train_size=train_size, random_state=0) \n","  X_trn = torch.from_numpy(X_trn)\n","  X_tst = torch.from_numpy(X_tst)\n","  y_trn = torch.from_numpy(y_trn)\n","  y_tst = torch.from_numpy(y_tst)\n","  return X_trn, X_tst, y_trn, y_tst\n","\n","X_trn, X_tst, y_trn, y_tst = get_and_split_data(0.70)\n","print(X.shape)\n","print(y.shape)\n","print(X_trn.shape)\n","print(X_tst.shape)"],"metadata":{"id":"VHL94hZUgoBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R_VcWolELo7Z"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# 2.1 Plain CNN"]},{"cell_type":"markdown","source":["**Complete the code below**"],"metadata":{"id":"qbzbwnPdudPU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfkJMHX8Lo7a"},"outputs":[],"source":["%%file plain_cnn.py\n","\n","torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n","\n","# Your code here. Aim for 8-11 lines.\n","drop_out_value = 0\n","\n","plain_cnn_model = torch.nn.Sequential( #120 X 120 X 1\n","    torch.nn.Conv2d(1, 8, kernel_size=5, padding=2), #120 X 120 X ?\n","    # torch.nn.Dropout(drop_out_value),\n","    torch.nn.ReLU(),\n","    torch.nn.MaxPool2d(kernel_size=2, stride=2), #60 X 60 X ?\n","\n","    torch.nn.Conv2d(8, 16, kernel_size=5, padding=2), #60 X 60 X ?\n","    # torch.nn.Dropout(drop_out_value),\n","    torch.nn.ReLU(),\n","    torch.nn.MaxPool2d(kernel_size=2, stride=2), #30 X 30 X ?\n","\n","    torch.nn.Conv2d(16, 32, kernel_size=5, padding=2), #30 X 30 X ?\n","    # torch.nn.Dropout(drop_out_value),\n","    torch.nn.ReLU(),\n","    torch.nn.MaxPool2d(kernel_size=2, stride=2), #15 X 15 X ?\n","\n","    torch.nn.Conv2d(32, 64, kernel_size=5, padding=2), #15 X 15 X ?\n","    # torch.nn.Dropout(drop_out_value),\n","    torch.nn.ReLU(),\n","    torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","    torch.nn.Conv2d(64, 128, kernel_size=5, padding=2), #15 X 15 X ?\n","    # torch.nn.Dropout(drop_out_value),\n","    torch.nn.ReLU(),\n","    torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","    torch.nn.Flatten(1,-1),\n","    torch.nn.Linear(1152,15)\n",")"]},{"cell_type":"markdown","source":["# 2.2 Hyperparameter Tuning"],"metadata":{"id":"7BHM6D_N4Kkv"}},{"cell_type":"code","source":["%%file data_prep.py\n","\n","import argparse\n","import numpy as np\n","import sklearn\n","import sklearn.preprocessing\n","import sklearn.neural_network\n","import torch\n","import copy\n","import torch.nn.functional as F\n","from orion.client import report_objective\n","\n","def get_data():\n","  data_retrieval = 0\n","\n","  if data_retrieval == 0:\n","    #!gdown 11Psi1ZZ2WJ-oHCG1UZcyjGQ1N1iFllDf\n","    path_for_npz = \"data.npz\"\n","\n","  else:\n","    colab_notebook_root = \"/content/drive/MyDrive/Colab Notebooks\"\n","    path_for_npz = colab_notebook_root + \"/COMP 432/Project/npz/data.npz\"\n","    if data_retrieval == 1:\n","        path_for_npz = \"G:/My Drive/Colab Notebooks/COMP 432/Project/npz/data.npz\"\n","    else:\n","        from google.colab import drive\n","        drive.mount(\"/content/drive\")\n","\n","  with np.load(path_for_npz) as data:\n","    X = data['X']\n","    X = X[:,:,:,2] # Get one channel\n","    X = X.reshape(-1, 1, 120, 120)\n","    X = X / 255.0 #Normalize data\n","\n","    y = data['y']\n","    # Encode labels to integers\n","    from sklearn import preprocessing\n","    le = preprocessing.LabelEncoder()\n","    le.fit(y)\n","    y = le.transform(y)\n","\n","    return X, y\n"],"metadata":{"id":"srx2oEOtKXke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%file plain_cnn_model.py\n","import torch\n","\n","def get_plain_cnn_model():\n","  plain_cnn_model = torch.nn.Sequential( #120 X 120 X 1\n","      torch.nn.Conv2d(1, 8, kernel_size=5, padding=2), #120 X 120 X ?\n","      # torch.nn.Dropout(drop_out_value),\n","      torch.nn.ReLU(),\n","      torch.nn.MaxPool2d(kernel_size=2, stride=2), #60 X 60 X ?\n","\n","      torch.nn.Conv2d(8, 16, kernel_size=5, padding=2), #60 X 60 X ?\n","      # torch.nn.Dropout(drop_out_value),\n","      torch.nn.ReLU(),\n","      torch.nn.MaxPool2d(kernel_size=2, stride=2), #30 X 30 X ?\n","\n","      torch.nn.Conv2d(16, 32, kernel_size=5, padding=2), #30 X 30 X ?\n","      # torch.nn.Dropout(drop_out_value),\n","      torch.nn.ReLU(),\n","      torch.nn.MaxPool2d(kernel_size=2, stride=2), #15 X 15 X ?\n","\n","      torch.nn.Conv2d(32, 64, kernel_size=5, padding=2), #15 X 15 X ?\n","      # torch.nn.Dropout(drop_out_value),\n","      torch.nn.ReLU(),\n","      torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","      torch.nn.Conv2d(64, 128, kernel_size=5, padding=2), #15 X 15 X ?\n","      # torch.nn.Dropout(drop_out_value),\n","      torch.nn.ReLU(),\n","      torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","      torch.nn.Flatten(1,-1),\n","      torch.nn.Linear(1152,15)\n","  )\n","\n","  return plain_cnn_model"],"metadata":{"id":"eAenD0HKPUVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%file train.py\n","\n","import argparse\n","import numpy as np\n","import sklearn\n","import sklearn.preprocessing\n","import sklearn.neural_network\n","import torch\n","import copy\n","import torch.nn.functional as F\n","from orion.client import report_objective # Orion\n","from data_prep import get_data\n","from plain_cnn_model import get_plain_cnn_model\n","\n","# def get_data():\n","#   data_retrieval = 0\n","\n","#   if data_retrieval == 0:\n","#     #!gdown 11Psi1ZZ2WJ-oHCG1UZcyjGQ1N1iFllDf\n","#     path_for_npz = \"data.npz\"\n","\n","#   else:\n","#     colab_notebook_root = \"/content/drive/MyDrive/Colab Notebooks\"\n","#     path_for_npz = colab_notebook_root + \"/COMP 432/Project/npz/data.npz\"\n","#     if data_retrieval == 1:\n","#         path_for_npz = \"G:/My Drive/Colab Notebooks/COMP 432/Project/npz/data.npz\"\n","#     else:\n","#         from google.colab import drive\n","#         drive.mount(\"/content/drive\")\n","\n","#   with np.load(path_for_npz) as data:\n","#     X = data['X']\n","#     X = X[:,:,:,2] # Get one channel\n","#     X = X.reshape(-1, 1, 120, 120)\n","#     X = X / 255.0 #Normalize data\n","\n","#     y = data['y']\n","#     # Encode labels to integers\n","#     from sklearn import preprocessing\n","#     le = preprocessing.LabelEncoder()\n","#     le.fit(y)\n","#     y = le.transform(y)\n","\n","#     return X, y\n","\n","torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n","\n","# Your code here. Aim for 8-11 lines.\n","drop_out_value = 0\n","\n","# plain_cnn_model = torch.nn.Sequential( #120 X 120 X 1\n","#     torch.nn.Conv2d(1, 8, kernel_size=5, padding=2), #120 X 120 X ?\n","#     # torch.nn.Dropout(drop_out_value),\n","#     torch.nn.ReLU(),\n","#     torch.nn.MaxPool2d(kernel_size=2, stride=2), #60 X 60 X ?\n","\n","#     torch.nn.Conv2d(8, 16, kernel_size=5, padding=2), #60 X 60 X ?\n","#     # torch.nn.Dropout(drop_out_value),\n","#     torch.nn.ReLU(),\n","#     torch.nn.MaxPool2d(kernel_size=2, stride=2), #30 X 30 X ?\n","\n","#     torch.nn.Conv2d(16, 32, kernel_size=5, padding=2), #30 X 30 X ?\n","#     # torch.nn.Dropout(drop_out_value),\n","#     torch.nn.ReLU(),\n","#     torch.nn.MaxPool2d(kernel_size=2, stride=2), #15 X 15 X ?\n","\n","#     torch.nn.Conv2d(32, 64, kernel_size=5, padding=2), #15 X 15 X ?\n","#     # torch.nn.Dropout(drop_out_value),\n","#     torch.nn.ReLU(),\n","#     torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","#     torch.nn.Conv2d(64, 128, kernel_size=5, padding=2), #15 X 15 X ?\n","#     # torch.nn.Dropout(drop_out_value),\n","#     torch.nn.ReLU(),\n","#     torch.nn.MaxPool2d(kernel_size=2, stride=2), #7 X 7 X ?\n","\n","#     torch.nn.Flatten(1,-1),\n","#     torch.nn.Linear(1152,15)\n","# )\n","\n","# Split train and test data (aim for 1 line)\n","def get_and_split_data(train_size):\n","  X, y = get_data()\n","  X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, train_size=train_size, random_state=0) \n","  X_val, X_tst, y_val, y_tst = sklearn.model_selection.train_test_split(X_tst, y_tst, train_size=0.5, random_state=0) \n","  X_trn = torch.from_numpy(X_trn)\n","  X_val = torch.from_numpy(X_val)\n","  X_tst = torch.from_numpy(X_tst)\n","  y_trn = torch.from_numpy(y_trn)\n","  y_val = torch.from_numpy(y_val)\n","  y_tst = torch.from_numpy(y_tst)\n","  return X_trn, X_val, X_tst, y_trn, y_val, y_tst\n","\n","device = \"cpu\"\n","if torch.cuda.is_available():\n","  device = \"cuda\"\n","\n","\n","def train(X_trn, y_trn, model, loss, args, optimizer):\n","  losses=[]\n","  accuracies=[]\n","  model.train()\n","\n","  for i in range(0, len(X_trn), args.batchsize):\n","    images = X_trn[i:i+args.batchsize].to(device)\n","    labels = y_trn[i:i+args.batchsize].to(device)\n","    #print('images.shape',images.shape)\n","    outputs = model(images)\n","    l = loss(outputs, labels)\n","    l.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","    losses.append(l.item())\n","    \n","    # Append Accuracy\n","    predictions = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    accuracies.append(sum(predictions == labels).item()/args.batchsize)\n","  return torch.tensor(losses).mean(), torch.tensor(accuracies).mean()\n","\n","def test(X_tst, y_tst, model, loss, args):\n","  losses=[]\n","  accuracies=[]\n","  err=0\n","  model.eval()\n","  for i in range(0, len(X_tst), args.batchsize):\n","    images = X_tst[i:i+args.batchsize].to(device)\n","    labels = y_tst[i:i+args.batchsize].to(device)\n","    outputs = model(images)\n","    l = loss(outputs, labels)\n","    losses.append(l.item())\n","\n","    predictions = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    accuracies.append(sum(predictions == labels).item()/args.batchsize)\n","    err = err + (predictions!=labels).sum().item()\n","  return torch.tensor(losses).mean(), err/len(X_tst), torch.tensor(accuracies).mean()\n","\n","def plot_epochs(X_trn, y_trn, X_tst, y_tst, model, loss, args, plot=False):\n","  train_losses=[]\n","  test_losses=[]\n","  train_accuracies=[]\n","  test_accuracies=[]\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weightdecay)\n","\n","  for epoch in range(args.epochs):\n","    train_loss, train_accuracy = train(X_trn, y_trn, model, loss, args, optimizer)\n","    test_loss, test_err, test_accuracy = test(X_tst, y_tst, model, loss, args)\n","    train_losses.append(train_loss)\n","    test_losses.append(test_loss)\n","    train_accuracies.append(train_accuracy)\n","    test_accuracies.append(test_accuracy)\n","    print('Epoch: {}  train_loss={:.4f}, test_loss={:.4f}, test_err={:.2f}%, train_accuracy={:.2f}%, test_accuracy={:.2f}%' \\\n","      .format(epoch+1, train_loss, test_loss, test_err*100, train_accuracy*100, test_accuracy*100))\n","\n","  if plot == True:\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1,2,1)\n","    plt.plot(train_losses, '-s', label='train')\n","    plt.plot(test_losses, '-s', label='test')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    plt.subplot(1,2,2)\n","    plt.plot(train_accuracies, '-s', label='train')\n","    plt.plot(test_accuracies, '-s', label='test')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    plt.show()\n","\n","  return train_accuracies[-1], test_accuracies[-1]\n","\n","\n","def orion_train():\n","    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","    parser.add_argument('--batchsize', type=int, default=64,\n","                        help='input batch size for training (default: 64)')\n","    parser.add_argument('--epochs', type=int, default=10, \n","                        help='number of epochs to train (default: 14)')\n","    parser.add_argument('--lr', type=float, default=0.01, \n","                        help='learning rate (default: 1.0)')\n","    parser.add_argument('--neurons', type=int, default=100, \n","                        help='number of neurons (default: 100)')\n","    parser.add_argument('--eval', type=bool, default=False, \n","                        help='If True it prints the test error (default: False)')\n","    parser.add_argument('--weightdecay', type=float, default=0, \n","                        help='weight decay (default: 0)')\n","    parser.add_argument(\"-f\", required=False)\n","    args = parser.parse_args()\n","    print(args)\n","\n","    # Select data\n","    X_trn, X_val, X_tst, y_trn, y_val, y_tst = get_and_split_data(0.70)\n","#    model = copy.deepcopy(plain_cnn_model).to(device)\n","    model = copy.deepcopy(get_plain_cnn_model()).to(device)\n","\n","    # Your code for defining loss, optimizer, and training loop here. Aim for 10-12 lines.\n","    loss = torch.nn.CrossEntropyLoss()\n","    train_score, val_score = plot_epochs(X_trn, y_trn, X_val, y_val, model, loss, args)\n","    valid_error = (100*(1 - val_score)).item()\n","    print(\"Valid Error (\\%): \" + str(valid_error))\n","\n","    report_objective(valid_error)\n","\n","    # if args.eval:\n","    #   test_error = 100*(1 - model.score(X_tst, y_tst))\n","    #   print(\"Test Error (\\%): \" + str(test_error))\n","\n","\n","if __name__ == '__main__':\n","    orion_train()"],"metadata":{"id":"ZctQU6BO3_Yn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --lr=0.001 --epochs=3 --batchsize=64 --neurons=20 --eval='True'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8V8ZoRj2F4F","executionInfo":{"status":"ok","timestamp":1681314850968,"user_tz":240,"elapsed":10290,"user":{"displayName":"Steven Markandu","userId":"11656348305876002039"}},"outputId":"588a3044-b1ce-4bf2-90c0-c89087726fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batchsize=64, epochs=3, lr=0.001, neurons=20, eval=True, weightdecay=0, f=None)\n","Epoch: 1  train_loss=2.4897, test_loss=1.9705, test_err=64.11%, train_accuracy=15.62%, test_accuracy=35.49%\n","Epoch: 2  train_loss=1.5483, test_loss=1.3213, test_err=47.63%, train_accuracy=44.74%, test_accuracy=51.79%\n","Epoch: 3  train_loss=1.0380, test_loss=0.9792, test_err=34.76%, train_accuracy=62.59%, test_accuracy=64.51%\n","Valid Error (\\%): 35.49107360839844\n","[{'name': 'objective', 'type': 'objective', 'value': 35.49107360839844}]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"n_stncBlzSVc"}},{"cell_type":"markdown","source":[],"metadata":{"id":"5dGEEcUPzSpL"}},{"cell_type":"code","source":["!orion hunt -n plain_cnn --exp-max-trials=50 python train.py  --lr~'choices([0.1,0.01,0.001,0.0001])'  --batchsize~'choices([32,64,128])' --epochs~'choices([5,10,15,20])' --weightdecay~'choices([1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0])'"],"metadata":{"id":"SBnLddcCf214"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using the best results obtained from hyperparameter tuning, we try the following:"],"metadata":{"id":"ITLhWHMQd-H5"}},{"cell_type":"code","source":["!orion hunt -n plain_cnn2 --exp-max-trials=50 python train.py  --lr~'choices([0.001])'  --batchsize~'choices([32])' --epochs~'choices([25,30,35,40])' --weightdecay~'choices([0])'"],"metadata":{"id":"YFTNdg_0D_Ce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --lr=0.001 --epochs=35 --batchsize=32 --weightdecay=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0QyvEF_eE9S","executionInfo":{"status":"ok","timestamp":1681316495005,"user_tz":240,"elapsed":26909,"user":{"displayName":"Steven Markandu","userId":"11656348305876002039"}},"outputId":"8942dacd-7ba7-487c-ec26-427253853363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batchsize=32, epochs=35, lr=0.001, neurons=100, eval=False, weightdecay=0.0, f=None)\n","Epoch: 1  train_loss=2.3448, test_loss=1.7112, test_err=55.30%, train_accuracy=19.57%, test_accuracy=44.20%\n","Epoch: 2  train_loss=1.3838, test_loss=1.1730, test_err=41.99%, train_accuracy=50.10%, test_accuracy=57.37%\n","Epoch: 3  train_loss=0.8866, test_loss=0.7553, test_err=29.57%, train_accuracy=68.32%, test_accuracy=69.64%\n","Epoch: 4  train_loss=0.5713, test_loss=0.6767, test_err=27.09%, train_accuracy=79.18%, test_accuracy=72.10%\n","Epoch: 5  train_loss=0.4336, test_loss=0.6797, test_err=23.25%, train_accuracy=84.13%, test_accuracy=75.89%\n","Epoch: 6  train_loss=0.3175, test_loss=0.4560, test_err=17.16%, train_accuracy=87.74%, test_accuracy=81.92%\n","Epoch: 7  train_loss=0.2400, test_loss=0.5061, test_err=16.70%, train_accuracy=90.96%, test_accuracy=82.37%\n","Epoch: 8  train_loss=0.1634, test_loss=0.4455, test_err=12.87%, train_accuracy=93.46%, test_accuracy=86.16%\n","Epoch: 9  train_loss=0.1302, test_loss=0.5204, test_err=14.67%, train_accuracy=94.76%, test_accuracy=84.38%\n","Epoch: 10  train_loss=0.1220, test_loss=0.5870, test_err=16.70%, train_accuracy=94.66%, test_accuracy=82.37%\n","Epoch: 11  train_loss=0.0878, test_loss=0.5115, test_err=12.64%, train_accuracy=96.30%, test_accuracy=86.38%\n","Epoch: 12  train_loss=0.0986, test_loss=0.6961, test_err=18.06%, train_accuracy=96.20%, test_accuracy=81.03%\n","Epoch: 13  train_loss=0.0805, test_loss=0.5177, test_err=12.87%, train_accuracy=96.68%, test_accuracy=86.16%\n","Epoch: 14  train_loss=0.0610, test_loss=0.5220, test_err=13.32%, train_accuracy=97.21%, test_accuracy=85.71%\n","Epoch: 15  train_loss=0.0327, test_loss=0.6741, test_err=16.25%, train_accuracy=98.22%, test_accuracy=82.81%\n","Epoch: 16  train_loss=0.0641, test_loss=0.5155, test_err=10.84%, train_accuracy=97.79%, test_accuracy=88.17%\n","Epoch: 17  train_loss=0.0163, test_loss=0.4805, test_err=10.38%, train_accuracy=98.85%, test_accuracy=88.62%\n","Epoch: 18  train_loss=0.0071, test_loss=0.4995, test_err=9.93%, train_accuracy=99.18%, test_accuracy=89.06%\n","Epoch: 19  train_loss=0.0011, test_loss=0.4442, test_err=9.48%, train_accuracy=99.33%, test_accuracy=89.51%\n","Epoch: 20  train_loss=0.0005, test_loss=0.4542, test_err=9.71%, train_accuracy=99.33%, test_accuracy=89.29%\n","Epoch: 21  train_loss=0.0004, test_loss=0.4613, test_err=9.71%, train_accuracy=99.33%, test_accuracy=89.29%\n","Epoch: 22  train_loss=0.0003, test_loss=0.4680, test_err=9.48%, train_accuracy=99.33%, test_accuracy=89.51%\n","Epoch: 23  train_loss=0.0003, test_loss=0.4742, test_err=9.48%, train_accuracy=99.33%, test_accuracy=89.51%\n","Epoch: 24  train_loss=0.0002, test_loss=0.4800, test_err=9.48%, train_accuracy=99.33%, test_accuracy=89.51%\n","Epoch: 25  train_loss=0.0002, test_loss=0.4856, test_err=9.48%, train_accuracy=99.33%, test_accuracy=89.51%\n","Epoch: 26  train_loss=0.0002, test_loss=0.4909, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 27  train_loss=0.0001, test_loss=0.4960, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 28  train_loss=0.0001, test_loss=0.5007, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 29  train_loss=0.0001, test_loss=0.5053, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 30  train_loss=0.0001, test_loss=0.5097, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 31  train_loss=0.0001, test_loss=0.5139, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 32  train_loss=0.0001, test_loss=0.5180, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 33  train_loss=0.0001, test_loss=0.5219, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 34  train_loss=0.0001, test_loss=0.5257, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Epoch: 35  train_loss=0.0001, test_loss=0.5294, test_err=9.26%, train_accuracy=99.33%, test_accuracy=89.73%\n","Valid Error (\\%): 10.26785945892334\n","[{'name': 'objective', 'type': 'objective', 'value': 10.26785945892334}]\n"]}]},{"cell_type":"code","source":["!orion info --name orion-tutorial2 --version 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAFMy1yz1vSD","executionInfo":{"status":"ok","timestamp":1681165384402,"user_tz":240,"elapsed":5766,"user":{"displayName":"Steven Markandu","userId":"11656348305876002039"}},"outputId":"5fd4d6b9-fdfd-415a-def7-c5ad33339018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Identification\n","==============\n","name: orion-tutorial2\n","version: 1\n","user: root\n","\n","\n","Commandline\n","===========\n","python train.py --lr~loguniform(1e-4, 0.1) --batchsize~choices([32,64,128]) --epochs~uniform(15, 50, discrete=True)\n","\n","\n","Config\n","======\n","max trials: 50\n","max broken: 3\n","working dir: \n","\n","\n","Algorithm\n","=========\n","random:\n","    seed: None\n","\n","\n","Space\n","=====\n","/batchsize: choices([32, 64, 128])\n","/epochs: uniform(15, 50, discrete=True)\n","/lr: loguniform(0.0001, 0.1)\n","\n","\n","Meta-data\n","=========\n","user: root\n","datetime: 2023-04-10 21:47:24.609277\n","orion version: 0.2.6.post294+g3a4b49f1\n","VCS:\n","\n","\n","\n","Parent experiment\n","=================\n","root:\n","parent:\n","adapter:\n","\n","\n","Stats\n","=====\n","No trials executed...\n","\n","\n"]}]},{"cell_type":"markdown","source":["# 2.3 Evaluating Plain CNN"],"metadata":{"id":"6lJt3FO8ci-e"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrLN9x2JLo7f","executionInfo":{"status":"ok","timestamp":1681201232436,"user_tz":240,"elapsed":54962,"user":{"displayName":"Steven Markandu","userId":"11656348305876002039"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ea53773-6b01-4fb5-e0b3-7b8aabfeea41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1  train_loss=2.4964, test_loss=2.0471, test_err=67.95%, train_accuracy=15.06%, test_accuracy=31.70%\n","Epoch: 2  train_loss=1.5477, test_loss=1.2488, test_err=44.13%, train_accuracy=44.84%, test_accuracy=55.25%\n","Epoch: 3  train_loss=1.0549, test_loss=0.9565, test_err=33.41%, train_accuracy=60.84%, test_accuracy=65.85%\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor(0.608), tensor(0.658))"]},"metadata":{},"execution_count":41}],"source":["# Hyperparameters\n","from argparse import Namespace\n","args = Namespace(batchsize=64, epochs=3, lr=0.001, neurons=100, weightdecay=0, eval=False,f=False)\n","\n","# # Your code to define loss function and optimizer here. Aim for 2 lines.\n","loss = torch.nn.CrossEntropyLoss()\n","# train(X_trn, y_trn, plain_cnn_model, loss, args)\n","# orion_train()\n","model = copy.deepcopy(plain_cnn_model)\n","plot_epochs(X_trn, y_trn, X_tst, y_tst, model.to(device), loss, args)\n"]}]}